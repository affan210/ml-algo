{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self, learning_rate=0.01, num_iterations=1000, tolerance=1e-4):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_iterations = num_iterations\n",
    "        self.tolerance = tolerance\n",
    "    \n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    def calculate_gradient(self, X, y, theta):\n",
    "        m = len(y)\n",
    "        z = np.dot(X, theta)\n",
    "        h = self.sigmoid(z)\n",
    "        gradient = np.dot(X.T, (h - y)) / m\n",
    "        return gradient\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        m, n = X.shape\n",
    "        self.theta = np.zeros(n)  # Initialize weights with zeros\n",
    "        prev_cost = float('inf')  # ensures that the first iteration of will certainly lead to a decrease in the cost function.\n",
    "        \n",
    "        for iteration in range(self.num_iterations):\n",
    "            gradient = self.calculate_gradient(X, y, self.theta)\n",
    "            self.theta -= self.learning_rate * gradient\n",
    "            \n",
    "            # Calculate the cost function (log-likelihood)\n",
    "            z = np.dot(X, self.theta)\n",
    "            h = self.sigmoid(z)\n",
    "            cost = -(1/m) * np.sum(y * np.log(h) + (1 - y) * np.log(1 - h))\n",
    "            \n",
    "            # Check for convergence based on tolerance\n",
    "            if abs(prev_cost - cost) < self.tolerance:\n",
    "                print(f\"Converged after {iteration + 1} iterations.\")\n",
    "                break\n",
    "            \n",
    "            prev_cost = cost\n",
    "    \n",
    "    def predict(self, X):\n",
    "        z = np.dot(X, self.theta)\n",
    "        h = self.sigmoid(z)\n",
    "        # Use a threshold of 0.5 for binary classification\n",
    "        predictions = (h >= 0.5).astype(int)\n",
    "        return predictions\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        z = np.dot(X, self.theta)\n",
    "        h = self.sigmoid(z)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"./datasets/heartdisease.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sex', 'ChestPainType', 'RestingECG', 'ExerciseAngina', 'ST_Slope']\n",
      "['Age', 'RestingBP', 'Cholesterol', 'FastingBS', 'MaxHR', 'Oldpeak', 'HeartDisease']\n",
      "['Sex', 'ChestPainType', 'FastingBS', 'RestingECG', 'ExerciseAngina', 'ST_Slope']\n",
      "      Column Name      Distinct Values\n",
      "0             Sex               [M, F]\n",
      "1   ChestPainType  [ATA, NAP, ASY, TA]\n",
      "2       FastingBS               [0, 1]\n",
      "3      RestingECG    [Normal, ST, LVH]\n",
      "4  ExerciseAngina               [N, Y]\n",
      "5        ST_Slope     [Up, Flat, Down]\n"
     ]
    }
   ],
   "source": [
    "categorical = df.select_dtypes(include=['object']).columns.to_list()\n",
    "numerical = df.select_dtypes(include=['number']).columns.to_list()\n",
    "print(categorical, numerical, sep=\"\\n\")\n",
    "# Get the number of unique values in each column\n",
    "unique_counts = df.nunique()\n",
    "# print(unique_counts)\n",
    "# Filter for columns with less than 10 unique values\n",
    "columns_with_less_than_10_unique = unique_counts[unique_counts < 10]\n",
    "encoding_df = df[columns_with_less_than_10_unique.index].drop(columns=[\"HeartDisease\"])\n",
    "print(encoding_df.columns.to_list())\n",
    "\n",
    "# Get distinct values for all columns\n",
    "distinct_values = [[col, encoding_df[col].unique()] for col in encoding_df.columns]\n",
    "# Create a DataFrame from the list of distinct values\n",
    "distinct_df = pd.DataFrame(distinct_values, columns=['Column Name', 'Distinct Values'])\n",
    "print(distinct_df)\n",
    "\n",
    "# # Print distinct values in each column\n",
    "# for column in encoding_df.columns:\n",
    "#     distinct_values = encoding_df[column].unique()\n",
    "#     print(f\"Distinct values in {column}: {distinct_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total #features with target: 12\n",
      "(918, 12)\n",
      "[[74 'M' 'ASY' 150 258 1 'ST' 130 'Y' 4.0 'Down']\n",
      " [61 'M' 'ASY' 148 203 0 'Normal' 161 'N' 0.0 'Up']]\n",
      "0    1\n",
      "1    1\n",
      "Name: HeartDisease, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "dataset = df.copy()\n",
    "print(\"total #features with target:\",len(dataset.columns.to_list()))\n",
    "print(dataset.shape)\n",
    "target_column = \"HeartDisease\"\n",
    "# Define the split ratio (e.g., 80% train, 20% test)\n",
    "split_ratio = 0.8\n",
    "# Calculate the number of rows for the training set\n",
    "train_size = int(len(df) * split_ratio)\n",
    "# Create a random permutation of row indices\n",
    "indices = np.random.permutation(len(df))\n",
    "# Split the indices into training and testing indices\n",
    "train_indices, test_indices = indices[:train_size], indices[train_size:]\n",
    "\n",
    "# Create the training and testing DataFrames\n",
    "X_train_df = dataset.drop(columns=[target_column]).iloc[train_indices]\n",
    "X_test_df = dataset.drop(columns=[target_column]).iloc[test_indices]\n",
    "\n",
    "y_train_df = dataset[target_column].iloc[train_indices]\n",
    "y_test_df = dataset[target_column].iloc[test_indices]\n",
    "\n",
    "# Optionally, reset the index for the new DataFrames if needed\n",
    "X_train_df.reset_index(drop=True, inplace=True)\n",
    "X_test_df.reset_index(drop=True, inplace=True)\n",
    "y_train_df.reset_index(drop=True, inplace=True)\n",
    "y_test_df.reset_index(drop=True, inplace=True)\n",
    "print(X_train_df[:2].to_numpy(), y_train_df[:2], sep=\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "categorical_features = encoding_df.columns.to_list()\n",
    "# Define your preprocessing steps\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot-encoder', OneHotEncoder(sparse_output=False, handle_unknown='ignore'))\n",
    "])\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "                    ('onehot-transformer', categorical_transformer, categorical_features)])\n",
    "# Create the full pipeline with preprocessing and the model\n",
    "model = Pipeline(steps=[('data-preprocessor', preprocessor),\n",
    "                        ('model', LogisticRegression(learning_rate=0.01, num_iterations=1000, tolerance=1e-4)\n",
    "                         )])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged after 747 iterations.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;data-preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;onehot-transformer&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;onehot-encoder&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                                 sparse_output=False))]),\n",
       "                                                  [&#x27;Sex&#x27;, &#x27;ChestPainType&#x27;,\n",
       "                                                   &#x27;FastingBS&#x27;, &#x27;RestingECG&#x27;,\n",
       "                                                   &#x27;ExerciseAngina&#x27;,\n",
       "                                                   &#x27;ST_Slope&#x27;])])),\n",
       "                (&#x27;model&#x27;,\n",
       "                 &lt;__main__.LogisticRegression object at 0x000001650467FE20&gt;)])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;data-preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;onehot-transformer&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;onehot-encoder&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                                 sparse_output=False))]),\n",
       "                                                  [&#x27;Sex&#x27;, &#x27;ChestPainType&#x27;,\n",
       "                                                   &#x27;FastingBS&#x27;, &#x27;RestingECG&#x27;,\n",
       "                                                   &#x27;ExerciseAngina&#x27;,\n",
       "                                                   &#x27;ST_Slope&#x27;])])),\n",
       "                (&#x27;model&#x27;,\n",
       "                 &lt;__main__.LogisticRegression object at 0x000001650467FE20&gt;)])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">data-preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;onehot-transformer&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;onehot-encoder&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                sparse_output=False))]),\n",
       "                                 [&#x27;Sex&#x27;, &#x27;ChestPainType&#x27;, &#x27;FastingBS&#x27;,\n",
       "                                  &#x27;RestingECG&#x27;, &#x27;ExerciseAngina&#x27;,\n",
       "                                  &#x27;ST_Slope&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">onehot-transformer</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Sex&#x27;, &#x27;ChestPainType&#x27;, &#x27;FastingBS&#x27;, &#x27;RestingECG&#x27;, &#x27;ExerciseAngina&#x27;, &#x27;ST_Slope&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;, sparse_output=False)</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>&lt;__main__.LogisticRegression object at 0x000001650467FE20&gt;</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('data-preprocessor',\n",
       "                 ColumnTransformer(transformers=[('onehot-transformer',\n",
       "                                                  Pipeline(steps=[('onehot-encoder',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                                 sparse_output=False))]),\n",
       "                                                  ['Sex', 'ChestPainType',\n",
       "                                                   'FastingBS', 'RestingECG',\n",
       "                                                   'ExerciseAngina',\n",
       "                                                   'ST_Slope'])])),\n",
       "                ('model',\n",
       "                 <__main__.LogisticRegression object at 0x000001650467FE20>)])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_df, y_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 85.87%\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_df)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = np.mean(y_pred == y_test_df)\n",
    "print(f\"Accuracy: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test_df[:1].to_dict(orient='list') #.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[1 1]\n",
      "[1 1]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "# Define a function for inference\n",
    "def predict_with_model(input_data, model):\n",
    "    if isinstance(input_data, dict):\n",
    "        # If input is a dictionary, convert it to a DataFrame with a single row\n",
    "        input_df = pd.DataFrame([input_data])\n",
    "    elif isinstance(input_data, list):\n",
    "        # If input is a list, check if it's a list of dictionaries or a list of scalar values\n",
    "        if isinstance(input_data[0], dict):\n",
    "            # If it's a list of dictionaries, convert it to a DataFrame\n",
    "            input_df = pd.DataFrame(input_data)\n",
    "        else:\n",
    "            # If it's a list of scalar values, assume it's a single row of data\n",
    "            # and convert it to a DataFrame with appropriate column names\n",
    "            input_df = pd.DataFrame([input_data], columns=['Age', 'Sex', 'ChestPainType', 'RestingBP', 'Cholesterol', 'FastingBS', 'RestingECG', 'MaxHR', 'ExerciseAngina', 'Oldpeak', 'ST_Slope'])\n",
    "    \n",
    "    X_input = input_df\n",
    "    # Make predictions on the input data\n",
    "    try:\n",
    "        predictions = model.predict(X_input)\n",
    "        # Or, if you need class probabilities (for classifiers)\n",
    "        # probabilities = model.predict_proba(X_input_transformed)\n",
    "\n",
    "        return predictions  # Return the model's predictions\n",
    "    except TypeError as te:\n",
    "        predictions = model.predict(pd.DataFrame(input_data))\n",
    "        \n",
    "        return predictions\n",
    "\n",
    "# Example usage\n",
    "# 1. Single dictionary\n",
    "input_dict1 = {\n",
    "    'Age': 58,\n",
    "    'Sex': 'F',\n",
    "    'ChestPainType': 'ATA',\n",
    "    'RestingBP': 180,\n",
    "    'Cholesterol': 393,\n",
    "    'FastingBS': 0,\n",
    "    'RestingECG': 'Normal',\n",
    "    'MaxHR': 110,\n",
    "    'ExerciseAngina': 'Y',\n",
    "    'Oldpeak': 1.0,\n",
    "    'ST_Slope': 'Flat'\n",
    "}\n",
    "\n",
    "# 2. List of dictionaries\n",
    "input_dict2 = [\n",
    "    {\n",
    "        'Age': 58,\n",
    "        'Sex': 'F',\n",
    "        'ChestPainType': 'ATA',\n",
    "        'RestingBP': 180,\n",
    "        'Cholesterol': 393,\n",
    "        'FastingBS': 0,\n",
    "        'RestingECG': 'Normal',\n",
    "        'MaxHR': 110,\n",
    "        'ExerciseAngina': 'Y',\n",
    "        'Oldpeak': 1.0,\n",
    "        'ST_Slope': 'Flat'\n",
    "    },\n",
    "    {\n",
    "        'Age': 23,\n",
    "        'Sex': 'F',\n",
    "        'ChestPainType': 'ata',\n",
    "        'RestingBP': 180,\n",
    "        'Cholesterol': 213,\n",
    "        'FastingBS': 1,\n",
    "        'RestingECG': 'Normal',\n",
    "        'MaxHR': 119,\n",
    "        'ExerciseAngina': 'N',\n",
    "        'Oldpeak': 0.0,\n",
    "        'ST_Slope': 'Flat'\n",
    "    }\n",
    "]\n",
    "\n",
    "# 3. List of dictionaries with series\n",
    "input_dict3 = {\n",
    "        'Age': [58, 23],\n",
    "        'Sex': ['F', 'F'],\n",
    "        'ChestPainType': ['ATA', 'ata'],\n",
    "        'RestingBP': [180, 180],\n",
    "        'Cholesterol': [393, 213],\n",
    "        'FastingBS': [0, 1],\n",
    "        'RestingECG': ['Normal', 'Normal'],\n",
    "        'MaxHR': [110, 119],\n",
    "        'ExerciseAngina': ['Y', 'N'],\n",
    "        'Oldpeak': [1.0, 0.0],\n",
    "        'ST_Slope': ['Flat', 'Flat']\n",
    "    }\n",
    "\n",
    "# 4. List\n",
    "input_list = [58, 'F', 'ATA', 180, 393, 0, 'Normal', 110, 'Y', 1.0, 'Flat']\n",
    "\n",
    "output1 = predict_with_model(input_dict1, model)\n",
    "output2 = predict_with_model(input_dict2, model)\n",
    "output3 = predict_with_model(input_dict3, model)\n",
    "output4 = predict_with_model(input_list, model)\n",
    "\n",
    "print(output1)\n",
    "print(output2)\n",
    "print(output3)\n",
    "print(output4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some sample data\n",
    "np.random.seed(0)\n",
    "X = np.random.randn(100, 2)\n",
    "y = (X[:, 0] + X[:, 1] > 0).astype(int)  # A simple linear decision boundary\n",
    "# Split the data into training and test sets (you should use a more robust method in practice)\n",
    "X_train, X_test = X[:80], X[80:]\n",
    "y_train, y_test = y[:80], y[80:]\n",
    "\n",
    "# Create and train the logistic regression model\n",
    "model = LogisticRegression(learning_rate=0.01, num_iterations=10000, tolerance=1e-4)\n",
    "model.fit(X_train, y_train)\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "print(f\"Accuracy: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(y_pred, y_true):\n",
    "    return np.mean(y_pred == y_true)\n",
    "\n",
    "def calculate_precision(y_pred, y_true):\n",
    "    true_positives = np.sum((y_pred == 1) & (y_true == 1))\n",
    "    false_positives = np.sum((y_pred == 1) & (y_true == 0))\n",
    "    return true_positives / (true_positives + false_positives)\n",
    "\n",
    "def calculate_recall(y_pred, y_true):\n",
    "    true_positives = np.sum((y_pred == 1) & (y_true == 1))\n",
    "    false_negatives = np.sum((y_pred == 0) & (y_true == 1))\n",
    "    return true_positives / (true_positives + false_negatives)\n",
    "\n",
    "def calculate_f1_score(y_pred, y_true):\n",
    "    precision = calculate_precision(y_pred, y_true)\n",
    "    recall = calculate_recall(y_pred, y_true)\n",
    "    return 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "def calculate_metric(metric_name, y_pred, y_true):\n",
    "    if metric_name == \"accuracy\":\n",
    "        return calculate_accuracy(y_pred, y_true)\n",
    "    elif metric_name == \"precision\":\n",
    "        return calculate_precision(y_pred, y_true)\n",
    "    elif metric_name == \"recall\":\n",
    "        return calculate_recall(y_pred, y_true)\n",
    "    elif metric_name == \"f1_score\":\n",
    "        return calculate_f1_score(y_pred, y_true)\n",
    "    elif metric_name == \"list_metrics\":\n",
    "        return [\"accuracy\", \"precision\", \"recall\", \"f1_score\"]\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid metric name. Available metrics: {', '.join(calculate_metric('list_metrics', None, None))}\")\n",
    "\n",
    "def calculate_metrics(y_pred, y_true):\n",
    "    metrics = {}\n",
    "    metrics[\"accuracy\"] = calculate_accuracy(y_pred, y_true)\n",
    "    metrics[\"precision\"] = calculate_precision(y_pred, y_true)\n",
    "    metrics[\"recall\"] = calculate_recall(y_pred, y_true)\n",
    "    metrics[\"f1_score\"] = calculate_f1_score(y_pred, y_true)\n",
    "    return metrics\n",
    "\n",
    "def calculate_roc_auc(y_prob, y_true, plot=False):\n",
    "    thresholds = np.linspace(0, 1, 100)  # Threshold values\n",
    "    tpr_list = []  # True Positive Rate (Sensitivity)\n",
    "    fpr_list = []  # False Positive Rate\n",
    "\n",
    "    for threshold in thresholds:\n",
    "        y_pred_thresholded = (y_prob >= threshold).astype(int)\n",
    "        true_positives = np.sum((y_pred_thresholded == 1) & (y_true == 1))\n",
    "        false_positives = np.sum((y_pred_thresholded == 1) & (y_true == 0))\n",
    "        true_negatives = np.sum((y_pred_thresholded == 0) & (y_true == 0))\n",
    "        false_negatives = np.sum((y_pred_thresholded == 0) & (y_true == 1))\n",
    "\n",
    "        tpr = true_positives / (true_positives + false_negatives)\n",
    "        fpr = false_positives / (false_positives + true_negatives)\n",
    "\n",
    "        tpr_list.append(tpr)\n",
    "        fpr_list.append(fpr)\n",
    "\n",
    "    auc = calculate_auc(tpr_list, fpr_list)\n",
    "\n",
    "    if plot:\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(fpr_list, tpr_list, linestyle='-', marker='.')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title(f'ROC Curve (AUC: {auc:.2f})')  # Include AUC score in the title\n",
    "        plt.grid(True)\n",
    "        # Add AUC score as text annotation on the plot\n",
    "        plt.annotate(f'AUC = {auc:.2f}', xy=(0.6, 0.4), xytext=(0.6, 0.7),\n",
    "                    #  arrowprops=dict(facecolor='black', shrink=0.05),\n",
    "                     fontsize=12, color='black', backgroundcolor='white')\n",
    "        plt.show()\n",
    "\n",
    "    return auc\n",
    "\n",
    "def calculate_auc(tpr, fpr):\n",
    "    auc = 0.0\n",
    "    for i in range(1, len(tpr)):\n",
    "        width = fpr[i] - fpr[i - 1]\n",
    "        height_avg = (tpr[i] + tpr[i - 1]) / 2\n",
    "        auc += width * height_avg\n",
    "    return auc\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # ... (training and prediction code)\n",
    "\n",
    "    # Calculate and print the requested metric or list available metrics\n",
    "    metric_name = \"list_metrics\"  # Change this to the metric you want to calculate or \"list_metrics\"\n",
    "    \n",
    "    if metric_name == \"list_metrics\":\n",
    "        print(\"Available metrics:\", calculate_metric(metric_name, None, None))\n",
    "    else:\n",
    "        metric_value = calculate_metric(metric_name, y_pred, y_test)\n",
    "        print(f\"{metric_name.capitalize()}: {metric_value*100:.2f}%\")\n",
    "\n",
    "    # Calculate and print a specific metric\n",
    "    metric_name = \"accuracy\"  # Change this to the metric you want\n",
    "    metric_value = calculate_metric(metric_name, y_pred, y_test)\n",
    "    print(f\"{metric_name.capitalize()}: {metric_value*100:.2f}%\")\n",
    "    \n",
    "    # Calculate and print all eligible metrics\n",
    "    calculated_metrics = calculate_metrics(y_pred, y_test)\n",
    "    for metric_name, metric_value in calculated_metrics.items():\n",
    "        print(f\"{metric_name.capitalize()}: {metric_value*100:.2f}%\")\n",
    "\n",
    "    # Calculate and print ROC AUC score\n",
    "    auc_score = calculate_roc_auc(y_prob, y_test, plot=True)\n",
    "    print(f\"ROC AUC Score: {auc_score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-algo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
